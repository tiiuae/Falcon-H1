<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Evaluations - Falcon H1</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/mono-blue.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Falcon H1</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="nav-item">
                                <a href="../deployment/" class="nav-link">Deployment</a>
                            </li>
                            <li class="nav-item">
                                <a href="./" class="nav-link active" aria-current="page">Evaluations</a>
                            </li>
                            <li class="nav-item">
                                <a href="../finetuning/" class="nav-link">Fine-Tuning Guidelines</a>
                            </li>
                            <li class="nav-item">
                                <a href="../post_training_details/" class="nav-link">Our settings</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../deployment/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../finetuning/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#evaluations" class="nav-link">Evaluations</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-05b" class="nav-link">Falcon-H1-0.5B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-05b-instruct" class="nav-link">Falcon-H1-0.5B-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-15b" class="nav-link">Falcon-H1-1.5B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-15b-instruct" class="nav-link">Falcon-H1-1.5B-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-15b-deep" class="nav-link">Falcon-H1-1.5B-Deep</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-15b-deep-instruct" class="nav-link">Falcon-H1-1.5B-Deep-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-3b" class="nav-link">Falcon-H1-3B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-3b-instruct" class="nav-link">Falcon-H1-3B-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-7b" class="nav-link">Falcon-H1-7B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-7b-instruct" class="nav-link">Falcon-H1-7B-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-34b" class="nav-link">Falcon-H1-34B</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#falcon-h1-34b-instruct" class="nav-link">Falcon-H1-34B-Instruct</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="evaluations">Evaluations</h1>
<p>We summarize our evaluation settings in the following table.</p>
<table>
<thead>
<tr>
<th>Task</th>
<th>Base models setting</th>
<th>Instruct models setting</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td>logprobs, 3-shot</td>
<td>logprobs, 3-shot</td>
</tr>
<tr>
<td>ARC-C</td>
<td>logprobs, 25-shot</td>
<td>logprobs, 0-shot</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>-</td>
<td>logprobs, 0-shot</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>logprobs, 10-shot</td>
<td>logprobs, 0-shot</td>
</tr>
<tr>
<td>Winogrande</td>
<td>logprobs, 5-shot</td>
<td>-</td>
</tr>
<tr>
<td>MMLU</td>
<td>logprobs, 5-shot</td>
<td>logprobs, 5-shot</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>strict match, 5-shot</td>
<td>strict match, 5-shot</td>
</tr>
<tr>
<td>MATH-500</td>
<td>-</td>
<td>accuracy</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td>math verify, 4-shot</td>
<td>-</td>
</tr>
<tr>
<td>AMC-23</td>
<td>-</td>
<td>average accuracy, 16 repetitions</td>
</tr>
<tr>
<td>AIME-24</td>
<td>-</td>
<td>average accuracy, 16 repetitions</td>
</tr>
<tr>
<td>AIME-25</td>
<td>-</td>
<td>average accuracy, 16 repetitions</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td>logprobs, 5-shot</td>
<td>logprobs, 5-shot</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td>-</td>
<td>average accuracy, 3 repetitions</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td>logprobs, 5-shot</td>
<td>logprobs, 5-shot</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td>subset of MMLU</td>
<td>subset of MMLU</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>pass@1</td>
<td>pass@1</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>pass@1</td>
<td>pass@1</td>
</tr>
<tr>
<td>MBPP</td>
<td>pass@1</td>
<td>pass@1</td>
</tr>
<tr>
<td>MBPP+</td>
<td>pass@1</td>
<td>pass@1</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>-</td>
<td>accuracy</td>
</tr>
<tr>
<td>CRUXEval</td>
<td>-</td>
<td>pass@1, input &amp; output average</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td>-</td>
<td>inst &amp; prompt average accuaracy</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td>-</td>
<td>LC winrate</td>
</tr>
<tr>
<td>MTBench</td>
<td>-</td>
<td>turn 1 &amp; 2 average</td>
</tr>
<tr>
<td>LiveBench</td>
<td>-</td>
<td>global_average</td>
</tr>
</tbody>
</table>
<p>The respective evaluation results for both base and instruct models can be found below</p>
<h2 id="falcon-h1-05b">Falcon-H1-0.5B</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-0.5B</th>
<th>Qwen3-0.6B</th>
<th>Qwen2.5-0.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>40.22</strong></td>
<td>36.07</td>
<td>32.62</td>
<td>30.26</td>
<td>30.72</td>
<td>35.24</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>55.04</strong></td>
<td>52.64</td>
<td>47.61</td>
<td>26.33</td>
<td>32.39</td>
<td>45.14</td>
</tr>
<tr>
<td>ARC-C</td>
<td>46.93</td>
<td>44.8</td>
<td>35.32</td>
<td>39.33</td>
<td>39.42</td>
<td><strong>47.87</strong></td>
</tr>
<tr>
<td>HellaSwag</td>
<td>56.3</td>
<td>53.51</td>
<td>51.79</td>
<td>62.94</td>
<td><strong>65.73</strong></td>
<td>62.3</td>
</tr>
<tr>
<td>Winogrande</td>
<td>59.43</td>
<td>60.54</td>
<td>56.83</td>
<td>62.59</td>
<td><strong>62.75</strong></td>
<td>61.17</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td><strong>60.2</strong></td>
<td>50.04</td>
<td>34.8</td>
<td>2.2</td>
<td>7.05</td>
<td>34.95</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>15.18</strong></td>
<td>9.29</td>
<td>4.23</td>
<td>1.21</td>
<td>0.98</td>
<td>3.4</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>29.7</strong></td>
<td>29.11</td>
<td>27.94</td>
<td>24.66</td>
<td>23.57</td>
<td>27.85</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>30.04</strong></td>
<td>22.99</td>
<td>18.98</td>
<td>11.31</td>
<td>11.8</td>
<td>16.11</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>57.12</strong></td>
<td>50.11</td>
<td>43.74</td>
<td>27.59</td>
<td>30.19</td>
<td>40.06</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>35.98</strong></td>
<td>31.71</td>
<td>29.27</td>
<td>6.71</td>
<td>18.9</td>
<td>10.37</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>31.1</strong></td>
<td>27.44</td>
<td>25.0</td>
<td>5.49</td>
<td>16.46</td>
<td>9.15</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>52.12</strong></td>
<td>51.06</td>
<td>40.74</td>
<td>12.7</td>
<td>35.98</td>
<td>12.43</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>43.39</strong></td>
<td>42.33</td>
<td>34.66</td>
<td>9.52</td>
<td>29.89</td>
<td>9.52</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-05b-instruct">Falcon-H1-0.5B-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-0.5B</th>
<th>Qwen3-0.6B</th>
<th>Qwen2.5-0.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>42.91</strong></td>
<td>32.95</td>
<td>33.26</td>
<td>35.86</td>
<td>33.21</td>
<td>34.47</td>
</tr>
<tr>
<td>ARC-C</td>
<td>37.8</td>
<td>31.06</td>
<td>33.28</td>
<td>34.13</td>
<td>34.64</td>
<td><strong>43.09</strong></td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>44.12</td>
<td><strong>51.65</strong></td>
<td>46.19</td>
<td>42.17</td>
<td>42.08</td>
<td>42.31</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>51.93</td>
<td>42.17</td>
<td>52.38</td>
<td>42.24</td>
<td>55.3</td>
<td><strong>58.53</strong></td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>53.4</strong></td>
<td>42.98</td>
<td>46.07</td>
<td>40.87</td>
<td>45.93</td>
<td>46.1</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td><strong>68.39</strong></td>
<td>42.61</td>
<td>38.51</td>
<td>42.38</td>
<td>44.28</td>
<td>44.05</td>
</tr>
<tr>
<td>MATH-500</td>
<td><strong>58.4</strong></td>
<td>46.0</td>
<td>27.8</td>
<td>45.4</td>
<td>13.2</td>
<td>19.8</td>
</tr>
<tr>
<td>AMC-23</td>
<td><strong>33.13</strong></td>
<td>27.97</td>
<td>12.5</td>
<td>19.22</td>
<td>7.19</td>
<td>6.87</td>
</tr>
<tr>
<td>AIME-24</td>
<td><strong>3.75</strong></td>
<td>2.71</td>
<td>0.62</td>
<td>0.42</td>
<td>1.46</td>
<td>0.41</td>
</tr>
<tr>
<td>AIME-25</td>
<td><strong>4.38</strong></td>
<td>1.67</td>
<td>0.21</td>
<td>1.25</td>
<td>0.0</td>
<td>0.21</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>29.95</strong></td>
<td>26.09</td>
<td>26.85</td>
<td>28.19</td>
<td>26.59</td>
<td>26.76</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td>27.95</td>
<td>25.08</td>
<td>24.24</td>
<td>21.55</td>
<td>25.08</td>
<td><strong>31.31</strong></td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>31.03</strong></td>
<td>16.95</td>
<td>18.73</td>
<td>14.46</td>
<td>16.2</td>
<td>18.49</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>54.55</strong></td>
<td>39.3</td>
<td>39.83</td>
<td>35.39</td>
<td>39.16</td>
<td>39.64</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>51.83</strong></td>
<td>41.46</td>
<td>36.59</td>
<td>40.85</td>
<td>34.15</td>
<td>22.56</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>45.12</strong></td>
<td>37.19</td>
<td>32.32</td>
<td>37.2</td>
<td>29.88</td>
<td>20.73</td>
</tr>
<tr>
<td>MBPP</td>
<td>42.59</td>
<td>56.08</td>
<td>46.83</td>
<td><strong>57.67</strong></td>
<td>33.6</td>
<td>20.63</td>
</tr>
<tr>
<td>MBPP+</td>
<td>33.07</td>
<td>47.08</td>
<td>39.68</td>
<td><strong>50.0</strong></td>
<td>29.37</td>
<td>17.2</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>7.05</td>
<td><strong>9.78</strong></td>
<td>2.94</td>
<td>5.09</td>
<td>2.35</td>
<td>0.78</td>
</tr>
<tr>
<td>CRUXEval</td>
<td><strong>25.75</strong></td>
<td>23.63</td>
<td>14.88</td>
<td>12.7</td>
<td>0.06</td>
<td>15.58</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td><strong>72.07</strong></td>
<td>62.16</td>
<td>32.11</td>
<td>61.48</td>
<td>55.34</td>
<td>54.26</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td>10.79</td>
<td>9.59</td>
<td>3.26</td>
<td><strong>17.87</strong></td>
<td>9.38</td>
<td>6.98</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>7.06</strong></td>
<td>5.75</td>
<td>4.71</td>
<td>7.03</td>
<td>6.37</td>
<td>6.03</td>
</tr>
<tr>
<td>LiveBench</td>
<td>20.8</td>
<td><strong>27.78</strong></td>
<td>14.27</td>
<td>18.79</td>
<td>14.97</td>
<td>14.1</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-15b">Falcon-H1-1.5B</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-1.5B</th>
<th>Qwen3-1.7B</th>
<th>Qwen2.5-1.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>46.57</strong></td>
<td>43.05</td>
<td>40.55</td>
<td>30.26</td>
<td>30.72</td>
<td>35.24</td>
</tr>
<tr>
<td>MMLU</td>
<td>61.81</td>
<td><strong>62.46</strong></td>
<td>61.13</td>
<td>26.33</td>
<td>32.39</td>
<td>45.14</td>
</tr>
<tr>
<td>ARC-C</td>
<td>53.24</td>
<td><strong>55.72</strong></td>
<td>54.27</td>
<td>39.33</td>
<td>39.42</td>
<td>47.87</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>66.76</td>
<td>67.09</td>
<td><strong>67.86</strong></td>
<td>62.94</td>
<td>65.73</td>
<td>62.3</td>
</tr>
<tr>
<td>Winogrande</td>
<td>65.59</td>
<td><strong>66.3</strong></td>
<td>64.56</td>
<td>62.59</td>
<td>62.75</td>
<td>61.17</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>52.01</td>
<td><strong>70.74</strong></td>
<td>63.0</td>
<td>2.2</td>
<td>7.05</td>
<td>34.95</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>20.39</strong></td>
<td>16.39</td>
<td>8.84</td>
<td>1.21</td>
<td>0.98</td>
<td>3.4</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td>29.11</td>
<td><strong>29.45</strong></td>
<td>28.36</td>
<td>24.66</td>
<td>23.57</td>
<td>27.85</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>35.53</strong></td>
<td>33.81</td>
<td>28.72</td>
<td>11.31</td>
<td>11.8</td>
<td>16.11</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>63.37</strong></td>
<td>61.53</td>
<td>54.93</td>
<td>27.59</td>
<td>30.19</td>
<td>40.06</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>50.0</td>
<td><strong>67.68</strong></td>
<td>35.37</td>
<td>6.71</td>
<td>18.9</td>
<td>10.37</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>42.68</td>
<td><strong>60.98</strong></td>
<td>29.27</td>
<td>5.49</td>
<td>16.46</td>
<td>9.15</td>
</tr>
<tr>
<td>MBPP</td>
<td>65.08</td>
<td><strong>67.72</strong></td>
<td>60.05</td>
<td>12.7</td>
<td>35.98</td>
<td>12.43</td>
</tr>
<tr>
<td>MBPP+</td>
<td>55.03</td>
<td><strong>58.99</strong></td>
<td>49.47</td>
<td>9.52</td>
<td>29.89</td>
<td>9.52</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-15b-instruct">Falcon-H1-1.5B-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-1.5B</th>
<th>Qwen3-1.7B</th>
<th>Qwen2.5-1.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>46.47</strong></td>
<td>35.18</td>
<td>42.41</td>
<td>35.86</td>
<td>33.21</td>
<td>34.47</td>
</tr>
<tr>
<td>ARC-C</td>
<td>42.06</td>
<td>34.81</td>
<td>40.53</td>
<td>34.13</td>
<td>34.64</td>
<td><strong>43.09</strong></td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>45.98</td>
<td><strong>49.39</strong></td>
<td>47.05</td>
<td>42.17</td>
<td>42.08</td>
<td>42.31</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>63.33</strong></td>
<td>49.27</td>
<td>62.23</td>
<td>42.24</td>
<td>55.3</td>
<td>58.53</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>62.03</strong></td>
<td>57.04</td>
<td>59.76</td>
<td>40.87</td>
<td>45.93</td>
<td>46.1</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td><strong>74.98</strong></td>
<td>69.83</td>
<td>57.47</td>
<td>42.38</td>
<td>44.28</td>
<td>44.05</td>
</tr>
<tr>
<td>MATH-500</td>
<td><strong>74.0</strong></td>
<td>73.0</td>
<td>48.4</td>
<td>45.4</td>
<td>13.2</td>
<td>19.8</td>
</tr>
<tr>
<td>AMC-23</td>
<td>43.59</td>
<td><strong>46.09</strong></td>
<td>24.06</td>
<td>19.22</td>
<td>7.19</td>
<td>6.87</td>
</tr>
<tr>
<td>AIME-24</td>
<td>11.25</td>
<td><strong>12.5</strong></td>
<td>2.29</td>
<td>0.42</td>
<td>1.46</td>
<td>0.41</td>
</tr>
<tr>
<td>AIME-25</td>
<td><strong>9.58</strong></td>
<td>8.12</td>
<td>1.25</td>
<td>1.25</td>
<td>0.0</td>
<td>0.21</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td>26.34</td>
<td>27.68</td>
<td>26.26</td>
<td><strong>28.19</strong></td>
<td>26.59</td>
<td>26.76</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td><strong>35.19</strong></td>
<td>33.33</td>
<td>25.59</td>
<td>21.55</td>
<td>25.08</td>
<td>31.31</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>37.8</strong></td>
<td>23.54</td>
<td>28.35</td>
<td>14.46</td>
<td>16.2</td>
<td>18.49</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>64.13</strong></td>
<td>54.3</td>
<td>54.04</td>
<td>35.39</td>
<td>39.16</td>
<td>39.64</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>68.29</strong></td>
<td>67.68</td>
<td>56.1</td>
<td>40.85</td>
<td>34.15</td>
<td>22.56</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>61.59</strong></td>
<td>60.96</td>
<td>50.61</td>
<td>37.2</td>
<td>29.88</td>
<td>20.73</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>64.81</strong></td>
<td>58.73</td>
<td><strong>64.81</strong></td>
<td>57.67</td>
<td>33.6</td>
<td>20.63</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>56.35</strong></td>
<td>49.74</td>
<td>56.08</td>
<td>50.0</td>
<td>29.37</td>
<td>17.2</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td><strong>17.61</strong></td>
<td>14.87</td>
<td>12.52</td>
<td>5.09</td>
<td>2.35</td>
<td>0.78</td>
</tr>
<tr>
<td>CRUXEval</td>
<td><strong>39.57</strong></td>
<td>18.88</td>
<td>34.76</td>
<td>12.7</td>
<td>0.06</td>
<td>15.58</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td><strong>80.66</strong></td>
<td>70.77</td>
<td>45.33</td>
<td>61.48</td>
<td>55.34</td>
<td>54.26</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td><strong>28.18</strong></td>
<td>21.89</td>
<td>9.54</td>
<td>17.87</td>
<td>9.38</td>
<td>6.98</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>8.46</strong></td>
<td>7.61</td>
<td>7.1</td>
<td>7.03</td>
<td>6.37</td>
<td>6.03</td>
</tr>
<tr>
<td>LiveBench</td>
<td>34.13</td>
<td><strong>40.73</strong></td>
<td>21.65</td>
<td>18.79</td>
<td>14.97</td>
<td>14.1</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-15b-deep">Falcon-H1-1.5B-Deep</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-1.5B-deep</th>
<th>Qwen3-1.7B</th>
<th>Qwen2.5-1.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>52.37</strong></td>
<td>43.05</td>
<td>40.55</td>
<td>30.26</td>
<td>30.72</td>
<td>35.24</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>66.29</strong></td>
<td>62.46</td>
<td>61.13</td>
<td>26.33</td>
<td>32.39</td>
<td>45.14</td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>55.89</strong></td>
<td>55.72</td>
<td>54.27</td>
<td>39.33</td>
<td>39.42</td>
<td>47.87</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>69.72</strong></td>
<td>67.09</td>
<td>67.86</td>
<td>62.94</td>
<td>65.73</td>
<td>62.3</td>
</tr>
<tr>
<td>Winogrande</td>
<td><strong>67.09</strong></td>
<td>66.3</td>
<td>64.56</td>
<td>62.59</td>
<td>62.75</td>
<td>61.17</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>68.69</td>
<td><strong>70.74</strong></td>
<td>63.0</td>
<td>2.2</td>
<td>7.05</td>
<td>34.95</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>24.77</strong></td>
<td>16.39</td>
<td>8.84</td>
<td>1.21</td>
<td>0.98</td>
<td>3.4</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>32.8</strong></td>
<td>29.45</td>
<td>28.36</td>
<td>24.66</td>
<td>23.57</td>
<td>27.85</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>41.07</strong></td>
<td>33.81</td>
<td>28.72</td>
<td>11.31</td>
<td>11.8</td>
<td>16.11</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>67.43</strong></td>
<td>61.53</td>
<td>54.93</td>
<td>27.59</td>
<td>30.19</td>
<td>40.06</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>52.44</td>
<td><strong>67.68</strong></td>
<td>35.37</td>
<td>6.71</td>
<td>18.9</td>
<td>10.37</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>46.34</td>
<td><strong>60.98</strong></td>
<td>29.27</td>
<td>5.49</td>
<td>16.46</td>
<td>9.15</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>70.9</strong></td>
<td>67.72</td>
<td>60.05</td>
<td>12.7</td>
<td>35.98</td>
<td>12.43</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>60.32</strong></td>
<td>58.99</td>
<td>49.47</td>
<td>9.52</td>
<td>29.89</td>
<td>9.52</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-15b-deep-instruct">Falcon-H1-1.5B-Deep-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-1.5B-deep</th>
<th>Qwen3-1.7B</th>
<th>Qwen2.5-1.5B</th>
<th>Gemma3-1B</th>
<th>Llama3.2-1B</th>
<th>Falcon3-1B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>54.43</strong></td>
<td>35.18</td>
<td>42.41</td>
<td>35.86</td>
<td>33.21</td>
<td>34.47</td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>43.86</strong></td>
<td>34.81</td>
<td>40.53</td>
<td>34.13</td>
<td>34.64</td>
<td>43.09</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td><strong>50.48</strong></td>
<td>49.39</td>
<td>47.05</td>
<td>42.17</td>
<td>42.08</td>
<td>42.31</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>65.54</strong></td>
<td>49.27</td>
<td>62.23</td>
<td>42.24</td>
<td>55.3</td>
<td>58.53</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>66.11</strong></td>
<td>57.04</td>
<td>59.76</td>
<td>40.87</td>
<td>45.93</td>
<td>46.1</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td><strong>82.34</strong></td>
<td>69.83</td>
<td>57.47</td>
<td>42.38</td>
<td>44.28</td>
<td>44.05</td>
</tr>
<tr>
<td>MATH-500</td>
<td><strong>77.8</strong></td>
<td>73.0</td>
<td>48.4</td>
<td>45.4</td>
<td>13.2</td>
<td>19.8</td>
</tr>
<tr>
<td>AMC-23</td>
<td><strong>56.56</strong></td>
<td>46.09</td>
<td>24.06</td>
<td>19.22</td>
<td>7.19</td>
<td>6.87</td>
</tr>
<tr>
<td>AIME-24</td>
<td><strong>14.37</strong></td>
<td>12.5</td>
<td>2.29</td>
<td>0.42</td>
<td>1.46</td>
<td>0.41</td>
</tr>
<tr>
<td>AIME-25</td>
<td><strong>11.04</strong></td>
<td>8.12</td>
<td>1.25</td>
<td>1.25</td>
<td>0.0</td>
<td>0.21</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>33.22</strong></td>
<td>27.68</td>
<td>26.26</td>
<td>28.19</td>
<td>26.59</td>
<td>26.76</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td><strong>40.57</strong></td>
<td>33.33</td>
<td>25.59</td>
<td>21.55</td>
<td>25.08</td>
<td>31.31</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>41.89</strong></td>
<td>23.54</td>
<td>28.35</td>
<td>14.46</td>
<td>16.2</td>
<td>18.49</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>67.3</strong></td>
<td>54.3</td>
<td>54.04</td>
<td>35.39</td>
<td>39.16</td>
<td>39.64</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>73.78</strong></td>
<td>67.68</td>
<td>56.1</td>
<td>40.85</td>
<td>34.15</td>
<td>22.56</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>68.9</strong></td>
<td>60.96</td>
<td>50.61</td>
<td>37.2</td>
<td>29.88</td>
<td>20.73</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>68.25</strong></td>
<td>58.73</td>
<td>64.81</td>
<td>57.67</td>
<td>33.6</td>
<td>20.63</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>56.61</strong></td>
<td>49.74</td>
<td>56.08</td>
<td>50.0</td>
<td>29.37</td>
<td>17.2</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td><strong>23.87</strong></td>
<td>14.87</td>
<td>12.52</td>
<td>5.09</td>
<td>2.35</td>
<td>0.78</td>
</tr>
<tr>
<td>CRUXEval</td>
<td><strong>52.32</strong></td>
<td>18.88</td>
<td>34.76</td>
<td>12.7</td>
<td>0.06</td>
<td>15.58</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td><strong>83.5</strong></td>
<td>70.77</td>
<td>45.33</td>
<td>61.48</td>
<td>55.34</td>
<td>54.26</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td><strong>27.12</strong></td>
<td>21.89</td>
<td>9.54</td>
<td>17.87</td>
<td>9.38</td>
<td>6.98</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>8.53</strong></td>
<td>7.61</td>
<td>7.1</td>
<td>7.03</td>
<td>6.37</td>
<td>6.03</td>
</tr>
<tr>
<td>LiveBench</td>
<td>36.83</td>
<td><strong>40.73</strong></td>
<td>21.65</td>
<td>18.79</td>
<td>14.97</td>
<td>14.1</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-3b">Falcon-H1-3B</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-3B</th>
<th>Qwen3-4B</th>
<th>Qwen2.5-3B</th>
<th>Gemma3-4B</th>
<th>Llama3.2-3B</th>
<th>Falcon3-3B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td>53.17</td>
<td><strong>56.88</strong></td>
<td>46.4</td>
<td>40.41</td>
<td>39.45</td>
<td>44.02</td>
</tr>
<tr>
<td>MMLU</td>
<td>68.39</td>
<td><strong>72.92</strong></td>
<td>65.56</td>
<td>59.41</td>
<td>55.94</td>
<td>56.77</td>
</tr>
<tr>
<td>ARC-C</td>
<td>61.35</td>
<td><strong>64.33</strong></td>
<td>56.57</td>
<td>58.36</td>
<td>51.02</td>
<td>55.12</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>73.85</td>
<td>75.74</td>
<td>74.6</td>
<td><strong>77.62</strong></td>
<td>76.39</td>
<td>67.13</td>
</tr>
<tr>
<td>Winogrande</td>
<td>68.11</td>
<td>72.3</td>
<td>71.03</td>
<td><strong>72.77</strong></td>
<td>72.22</td>
<td>65.11</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>68.31</td>
<td><strong>81.65</strong></td>
<td>74.6</td>
<td>37.6</td>
<td>27.82</td>
<td>64.67</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>25.83</strong></td>
<td>24.47</td>
<td>16.09</td>
<td>6.95</td>
<td>1.74</td>
<td>11.56</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td>32.63</td>
<td><strong>34.9</strong></td>
<td>28.44</td>
<td>29.78</td>
<td>28.78</td>
<td>29.78</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td>40.58</td>
<td><strong>46.18</strong></td>
<td>32.12</td>
<td>28.34</td>
<td>25.08</td>
<td>29.03</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td>69.55</td>
<td><strong>75.58</strong></td>
<td>62.23</td>
<td>51.7</td>
<td>47.67</td>
<td>55.34</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>59.15</td>
<td><strong>74.39</strong></td>
<td>42.68</td>
<td>33.54</td>
<td>29.27</td>
<td>36.59</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>53.66</td>
<td><strong>68.9</strong></td>
<td>35.37</td>
<td>28.05</td>
<td>26.22</td>
<td>31.71</td>
</tr>
<tr>
<td>MBPP</td>
<td>71.43</td>
<td><strong>74.6</strong></td>
<td>59.52</td>
<td>60.05</td>
<td>48.94</td>
<td>51.85</td>
</tr>
<tr>
<td>MBPP+</td>
<td>57.94</td>
<td><strong>63.76</strong></td>
<td>50.53</td>
<td>51.32</td>
<td>39.42</td>
<td>42.06</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-3b-instruct">Falcon-H1-3B-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-3B</th>
<th>Qwen3-4B</th>
<th>Qwen2.5-3B</th>
<th>Gemma3-4B</th>
<th>Llama3.2-3B</th>
<th>Falcon3-3B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>53.69</strong></td>
<td>51.07</td>
<td>46.55</td>
<td>50.01</td>
<td>41.47</td>
<td>45.02</td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>49.57</strong></td>
<td>37.71</td>
<td>43.77</td>
<td>44.88</td>
<td>44.88</td>
<td>48.21</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>53.19</td>
<td>51.75</td>
<td><strong>58.11</strong></td>
<td>51.68</td>
<td>50.27</td>
<td>50.06</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>69.85</strong></td>
<td>55.31</td>
<td>64.21</td>
<td>47.68</td>
<td>63.74</td>
<td>64.24</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>68.3</strong></td>
<td>67.01</td>
<td>65.09</td>
<td>59.53</td>
<td>61.74</td>
<td>56.76</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td><strong>84.76</strong></td>
<td>80.44</td>
<td>57.54</td>
<td>77.41</td>
<td>77.26</td>
<td>74.68</td>
</tr>
<tr>
<td>MATH-500</td>
<td>74.2</td>
<td><strong>85.0</strong></td>
<td>64.2</td>
<td>76.4</td>
<td>41.2</td>
<td>54.2</td>
</tr>
<tr>
<td>AMC-23</td>
<td>55.63</td>
<td><strong>66.88</strong></td>
<td>39.84</td>
<td>48.12</td>
<td>22.66</td>
<td>29.69</td>
</tr>
<tr>
<td>AIME-24</td>
<td>11.88</td>
<td><strong>22.29</strong></td>
<td>6.25</td>
<td>6.67</td>
<td>11.67</td>
<td>3.96</td>
</tr>
<tr>
<td>AIME-25</td>
<td>13.33</td>
<td><strong>18.96</strong></td>
<td>3.96</td>
<td>13.33</td>
<td>0.21</td>
<td>2.29</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>33.89</strong></td>
<td>28.02</td>
<td>28.69</td>
<td>29.19</td>
<td>28.94</td>
<td>28.69</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td>38.72</td>
<td><strong>40.74</strong></td>
<td>35.69</td>
<td>28.62</td>
<td>29.97</td>
<td>29.29</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>43.69</strong></td>
<td>29.75</td>
<td>32.76</td>
<td>29.71</td>
<td>27.44</td>
<td>29.71</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>69.93</strong></td>
<td>67.46</td>
<td>59.78</td>
<td>52.17</td>
<td>51.92</td>
<td>56.11</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>76.83</td>
<td><strong>84.15</strong></td>
<td>73.78</td>
<td>67.07</td>
<td>54.27</td>
<td>52.44</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>70.73</td>
<td><strong>76.83</strong></td>
<td>68.29</td>
<td>61.59</td>
<td>50.0</td>
<td>45.73</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>79.63</strong></td>
<td>68.78</td>
<td>72.75</td>
<td>77.78</td>
<td>62.17</td>
<td>61.9</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>67.46</strong></td>
<td>59.79</td>
<td>60.85</td>
<td>66.93</td>
<td>50.53</td>
<td>55.29</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>26.81</td>
<td><strong>39.92</strong></td>
<td>11.74</td>
<td>21.14</td>
<td>2.74</td>
<td>3.13</td>
</tr>
<tr>
<td>CRUXEval</td>
<td>56.25</td>
<td><strong>69.63</strong></td>
<td>43.26</td>
<td>52.13</td>
<td>17.75</td>
<td>44.38</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td><strong>85.05</strong></td>
<td>84.01</td>
<td>64.26</td>
<td>77.01</td>
<td>74.0</td>
<td>69.1</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td>31.09</td>
<td>36.51</td>
<td>17.37</td>
<td><strong>39.64</strong></td>
<td>19.69</td>
<td>14.82</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>8.72</strong></td>
<td>8.45</td>
<td>7.79</td>
<td>8.24</td>
<td>7.96</td>
<td>7.79</td>
</tr>
<tr>
<td>LiveBench</td>
<td>36.86</td>
<td><strong>51.34</strong></td>
<td>27.32</td>
<td>36.7</td>
<td>26.37</td>
<td>26.01</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-7b">Falcon-H1-7B</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-7B</th>
<th>Qwen3-8B</th>
<th>Qwen2.5-7B</th>
<th>Gemma3-12B</th>
<th>Llama3.1-8B</th>
<th>Falcon3-7B</th>
<th>Falcon3-10B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>60.61</strong></td>
<td>58.44</td>
<td>53.72</td>
<td>54.33</td>
<td>46.52</td>
<td>50.88</td>
<td>59.3</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>77.38</strong></td>
<td>76.63</td>
<td>74.17</td>
<td>74.23</td>
<td>65.17</td>
<td>69.98</td>
<td>73.22</td>
</tr>
<tr>
<td>ARC-C</td>
<td>65.19</td>
<td><strong>67.75</strong></td>
<td>63.91</td>
<td>67.58</td>
<td>57.68</td>
<td>62.71</td>
<td>67.49</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>81.26</td>
<td>79.6</td>
<td>80.2</td>
<td><strong>84.22</strong></td>
<td>81.97</td>
<td>76.69</td>
<td>79.64</td>
</tr>
<tr>
<td>Winogrande</td>
<td>79.01</td>
<td>76.8</td>
<td>76.01</td>
<td><strong>79.79</strong></td>
<td>77.11</td>
<td>73.64</td>
<td>79.01</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>73.46</td>
<td>83.02</td>
<td><strong>83.09</strong></td>
<td>71.19</td>
<td>49.51</td>
<td>76.95</td>
<td>82.11</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>34.67</strong></td>
<td>28.85</td>
<td>22.58</td>
<td>17.22</td>
<td>6.57</td>
<td>20.09</td>
<td>25.38</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>36.58</strong></td>
<td>35.65</td>
<td>32.3</td>
<td>34.56</td>
<td>31.46</td>
<td>35.07</td>
<td>35.4</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>48.38</strong></td>
<td>48.25</td>
<td>43.55</td>
<td>42.72</td>
<td>32.71</td>
<td>39.23</td>
<td>42.45</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td>77.2</td>
<td><strong>78.53</strong></td>
<td>71.04</td>
<td>68.51</td>
<td>55.72</td>
<td>67.71</td>
<td>70.85</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>67.68</td>
<td><strong>87.8</strong></td>
<td>57.32</td>
<td>45.12</td>
<td>39.02</td>
<td>50.0</td>
<td>51.83</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>63.41</td>
<td><strong>82.32</strong></td>
<td>48.78</td>
<td>36.59</td>
<td>31.71</td>
<td>43.29</td>
<td>44.51</td>
</tr>
<tr>
<td>MBPP</td>
<td><strong>78.57</strong></td>
<td>75.13</td>
<td>76.72</td>
<td>73.02</td>
<td>61.38</td>
<td>67.99</td>
<td>73.54</td>
</tr>
<tr>
<td>MBPP+</td>
<td><strong>67.2</strong></td>
<td>64.02</td>
<td>63.49</td>
<td>59.79</td>
<td>51.32</td>
<td>57.14</td>
<td>61.38</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-7b-instruct">Falcon-H1-7B-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-7B</th>
<th>Qwen3-8B</th>
<th>Qwen2.5-7B</th>
<th>Gemma3-12B</th>
<th>Llama3.1-8B</th>
<th>Falcon3-7B</th>
<th>Falcon3-10B</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td>62.28</td>
<td>47.47</td>
<td>53.76</td>
<td><strong>63.36</strong></td>
<td>48.58</td>
<td>52.12</td>
<td>58.09</td>
</tr>
<tr>
<td>ARC-C</td>
<td><strong>59.98</strong></td>
<td>42.06</td>
<td>41.38</td>
<td>51.96</td>
<td>52.39</td>
<td>54.35</td>
<td>54.44</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>59.91</td>
<td>53.19</td>
<td><strong>62.41</strong></td>
<td>61.02</td>
<td>52.99</td>
<td>55.58</td>
<td>55.05</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>75.92</strong></td>
<td>60.56</td>
<td>63.4</td>
<td>55.63</td>
<td>71.28</td>
<td>71.81</td>
<td>75.57</td>
</tr>
<tr>
<td>MMLU</td>
<td><strong>76.83</strong></td>
<td>71.56</td>
<td>73.64</td>
<td>72.5</td>
<td>68.67</td>
<td>70.81</td>
<td>74.01</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>81.65</td>
<td>78.92</td>
<td>71.95</td>
<td><strong>87.49</strong></td>
<td>82.49</td>
<td>81.05</td>
<td>85.06</td>
</tr>
<tr>
<td>MATH-500</td>
<td>73.4</td>
<td>83.8</td>
<td>75.8</td>
<td><strong>86.2</strong></td>
<td>45.8</td>
<td>69.0</td>
<td>68.6</td>
</tr>
<tr>
<td>AMC-23</td>
<td>56.72</td>
<td><strong>70.78</strong></td>
<td>53.91</td>
<td>66.88</td>
<td>22.81</td>
<td>40.0</td>
<td>45.78</td>
</tr>
<tr>
<td>AIME-24</td>
<td>16.04</td>
<td><strong>28.33</strong></td>
<td>12.29</td>
<td>22.5</td>
<td>5.42</td>
<td>8.75</td>
<td>9.79</td>
</tr>
<tr>
<td>AIME-25</td>
<td>13.96</td>
<td><strong>19.17</strong></td>
<td>9.58</td>
<td>18.75</td>
<td>0.42</td>
<td>6.25</td>
<td>5.42</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>36.33</strong></td>
<td>25.84</td>
<td>31.79</td>
<td>33.98</td>
<td>32.72</td>
<td>31.21</td>
<td>33.39</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td><strong>56.9</strong></td>
<td>43.1</td>
<td>33.0</td>
<td>37.71</td>
<td>31.31</td>
<td>37.21</td>
<td>34.68</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>51.75</strong></td>
<td>34.64</td>
<td>43.23</td>
<td>39.88</td>
<td>36.42</td>
<td>40.73</td>
<td>44.05</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>77.61</strong></td>
<td>66.89</td>
<td>69.36</td>
<td>66.54</td>
<td>59.31</td>
<td>67.43</td>
<td>70.57</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>86.59</strong></td>
<td>84.75</td>
<td>82.32</td>
<td>84.76</td>
<td>68.29</td>
<td>71.95</td>
<td>82.32</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>81.1</strong></td>
<td>79.27</td>
<td>73.78</td>
<td>75.61</td>
<td>61.59</td>
<td>65.85</td>
<td>75.0</td>
</tr>
<tr>
<td>MBPP</td>
<td>80.69</td>
<td>71.96</td>
<td>79.63</td>
<td><strong>85.71</strong></td>
<td>68.25</td>
<td>77.25</td>
<td>73.28</td>
</tr>
<tr>
<td>MBPP+</td>
<td>68.78</td>
<td>62.7</td>
<td>68.25</td>
<td><strong>72.22</strong></td>
<td>55.03</td>
<td>65.87</td>
<td>64.02</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>35.03</td>
<td><strong>45.6</strong></td>
<td>32.68</td>
<td>30.92</td>
<td>15.85</td>
<td>12.72</td>
<td>19.77</td>
</tr>
<tr>
<td>CRUXEval</td>
<td>66.51</td>
<td><strong>72.7</strong></td>
<td>56.9</td>
<td>67.67</td>
<td>21.57</td>
<td>55.0</td>
<td>59.57</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td><strong>85.35</strong></td>
<td>83.43</td>
<td>75.25</td>
<td>81.51</td>
<td>77.04</td>
<td>76.59</td>
<td>78.84</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td>40.23</td>
<td><strong>46.13</strong></td>
<td>29.48</td>
<td>43.55</td>
<td>25.48</td>
<td>27.56</td>
<td>24.31</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>8.85</strong></td>
<td>8.74</td>
<td>8.45</td>
<td>8.69</td>
<td>8.29</td>
<td>8.73</td>
<td>8.46</td>
</tr>
<tr>
<td>LiveBench</td>
<td>45.74</td>
<td><strong>56.19</strong></td>
<td>37.13</td>
<td>49.23</td>
<td>31.73</td>
<td>32.35</td>
<td>34.3</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-34b">Falcon-H1-34B</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-34B</th>
<th>Qwen2.5-72B</th>
<th>Qwen2.5-32B</th>
<th>Gemma3-27B</th>
<th>Llama3.1-70B</th>
<th>Llama4-scout</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td><strong>69.36</strong></td>
<td>67.77</td>
<td>67.45</td>
<td>61.6</td>
<td>62.78</td>
<td>61.71</td>
</tr>
<tr>
<td>MMLU</td>
<td>83.46</td>
<td><strong>85.96</strong></td>
<td>83.18</td>
<td>78.32</td>
<td>78.49</td>
<td>77.98</td>
</tr>
<tr>
<td>ARC-C</td>
<td>71.25</td>
<td><strong>72.44</strong></td>
<td>70.48</td>
<td>70.31</td>
<td>69.2</td>
<td>62.97</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>85.68</td>
<td>87.57</td>
<td>85.13</td>
<td>86.19</td>
<td><strong>87.78</strong></td>
<td>84.01</td>
</tr>
<tr>
<td>Winogrande</td>
<td>82.72</td>
<td>83.74</td>
<td>82.32</td>
<td>82.4</td>
<td><strong>85.32</strong></td>
<td>78.93</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>76.5</td>
<td>89.76</td>
<td><strong>90.14</strong></td>
<td>81.35</td>
<td>80.52</td>
<td>83.24</td>
</tr>
<tr>
<td>MATH lvl5</td>
<td><strong>40.71</strong></td>
<td>38.14</td>
<td>36.4</td>
<td>25.38</td>
<td>18.81</td>
<td>27.19</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>42.7</strong></td>
<td>42.28</td>
<td>39.68</td>
<td>35.82</td>
<td>36.49</td>
<td>35.99</td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td>57.18</td>
<td><strong>60.22</strong></td>
<td>58.05</td>
<td>49.64</td>
<td>47.07</td>
<td>50.16</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td>83.82</td>
<td><strong>84.81</strong></td>
<td>82.81</td>
<td>76.59</td>
<td>70.35</td>
<td>72.57</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td><strong>70.12</strong></td>
<td>59.15</td>
<td>59.76</td>
<td>48.78</td>
<td>57.32</td>
<td>57.32</td>
</tr>
<tr>
<td>HumanEval+</td>
<td><strong>64.63</strong></td>
<td>51.22</td>
<td>51.83</td>
<td>40.85</td>
<td>50.61</td>
<td>48.78</td>
</tr>
<tr>
<td>MBPP</td>
<td>83.33</td>
<td><strong>87.04</strong></td>
<td>83.07</td>
<td>76.19</td>
<td>78.84</td>
<td>77.78</td>
</tr>
<tr>
<td>MBPP+</td>
<td>70.37</td>
<td><strong>70.63</strong></td>
<td>68.78</td>
<td>61.64</td>
<td>66.67</td>
<td>64.29</td>
</tr>
</tbody>
</table>
<h2 id="falcon-h1-34b-instruct">Falcon-H1-34B-Instruct</h2>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>Falcon-H1-34B</th>
<th>Qwen3-32B</th>
<th>Qwen2.5-72B</th>
<th>Qwen2.5-32B</th>
<th>Gemma3-27B</th>
<th>Llama3.3-70B</th>
<th>Llama4-scout</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>General</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>BBH</td>
<td>70.68</td>
<td>62.47</td>
<td><strong>72.52</strong></td>
<td>68.72</td>
<td>67.28</td>
<td>69.15</td>
<td>64.9</td>
</tr>
<tr>
<td>ARC-C</td>
<td>61.01</td>
<td>48.98</td>
<td>46.59</td>
<td>44.54</td>
<td>54.52</td>
<td><strong>63.65</strong></td>
<td>56.14</td>
</tr>
<tr>
<td>TruthfulQA</td>
<td>65.27</td>
<td>58.58</td>
<td>69.8</td>
<td><strong>70.28</strong></td>
<td>64.26</td>
<td>66.15</td>
<td>62.74</td>
</tr>
<tr>
<td>HellaSwag</td>
<td><strong>81.94</strong></td>
<td>68.89</td>
<td>68.79</td>
<td>73.95</td>
<td>57.25</td>
<td>70.24</td>
<td>65.03</td>
</tr>
<tr>
<td>MMLU</td>
<td>84.05</td>
<td>80.89</td>
<td><strong>84.42</strong></td>
<td>82.8</td>
<td>78.01</td>
<td>82.08</td>
<td>80.4</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GSM8k</td>
<td>83.62</td>
<td>88.78</td>
<td>82.26</td>
<td>78.47</td>
<td>90.37</td>
<td><strong>93.71</strong></td>
<td>90.37</td>
</tr>
<tr>
<td>MATH-500</td>
<td>83.8</td>
<td>82.0</td>
<td>83.6</td>
<td>82.2</td>
<td><strong>90.0</strong></td>
<td>70.6</td>
<td>83.2</td>
</tr>
<tr>
<td>AMC-23</td>
<td>69.38</td>
<td>67.34</td>
<td>67.34</td>
<td>68.75</td>
<td><strong>77.81</strong></td>
<td>39.38</td>
<td>69.06</td>
</tr>
<tr>
<td>AIME-24</td>
<td>23.75</td>
<td>27.71</td>
<td>17.29</td>
<td>17.92</td>
<td>27.5</td>
<td>12.92</td>
<td><strong>27.92</strong></td>
</tr>
<tr>
<td>AIME-25</td>
<td>16.67</td>
<td>19.79</td>
<td>15.21</td>
<td>11.46</td>
<td><strong>22.71</strong></td>
<td>1.25</td>
<td>8.96</td>
</tr>
<tr>
<td><strong>Science</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPQA</td>
<td><strong>41.53</strong></td>
<td>30.2</td>
<td>37.67</td>
<td>34.31</td>
<td>36.49</td>
<td>31.99</td>
<td>31.8</td>
</tr>
<tr>
<td>GPQA_Diamond</td>
<td>49.66</td>
<td>49.49</td>
<td>44.95</td>
<td>40.74</td>
<td>47.47</td>
<td>42.09</td>
<td><strong>51.18</strong></td>
</tr>
<tr>
<td>MMLU-Pro</td>
<td><strong>58.73</strong></td>
<td>54.68</td>
<td>56.35</td>
<td>56.63</td>
<td>47.81</td>
<td>53.29</td>
<td>55.58</td>
</tr>
<tr>
<td>MMLU-stem</td>
<td><strong>83.57</strong></td>
<td>81.64</td>
<td>82.59</td>
<td>82.37</td>
<td>73.55</td>
<td>74.88</td>
<td>75.2</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>HumanEval</td>
<td>87.2</td>
<td><strong>90.85</strong></td>
<td>87.2</td>
<td>90.24</td>
<td>86.59</td>
<td>83.53</td>
<td>85.4</td>
</tr>
<tr>
<td>HumanEval+</td>
<td>81.71</td>
<td><strong>85.37</strong></td>
<td>80.49</td>
<td>82.32</td>
<td>78.05</td>
<td>79.87</td>
<td>78.7</td>
</tr>
<tr>
<td>MBPP</td>
<td>83.86</td>
<td>86.24</td>
<td><strong>89.68</strong></td>
<td>87.83</td>
<td>88.36</td>
<td>88.09</td>
<td>81.5</td>
</tr>
<tr>
<td>MBPP+</td>
<td>71.43</td>
<td>71.96</td>
<td><strong>75.4</strong></td>
<td>74.07</td>
<td>74.07</td>
<td>73.81</td>
<td>64.8</td>
</tr>
<tr>
<td>LiveCodeBench</td>
<td>49.71</td>
<td>45.01</td>
<td><strong>54.6</strong></td>
<td>49.12</td>
<td>39.53</td>
<td>40.31</td>
<td>40.12</td>
</tr>
<tr>
<td>CRUXEval</td>
<td>73.07</td>
<td><strong>78.45</strong></td>
<td>75.63</td>
<td>73.5</td>
<td>74.82</td>
<td>69.53</td>
<td>68.32</td>
</tr>
<tr>
<td><strong>Instruction Following</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IFEval</td>
<td>89.37</td>
<td>86.97</td>
<td>86.35</td>
<td>81.79</td>
<td>83.19</td>
<td><strong>89.94</strong></td>
<td>86.32</td>
</tr>
<tr>
<td>Alpaca-Eval</td>
<td>48.32</td>
<td><strong>64.21</strong></td>
<td>49.29</td>
<td>39.26</td>
<td>56.16</td>
<td>38.27</td>
<td>36.26</td>
</tr>
<tr>
<td>MTBench</td>
<td><strong>9.2</strong></td>
<td>9.05</td>
<td>9.16</td>
<td>9.09</td>
<td>8.75</td>
<td>8.98</td>
<td>8.98</td>
</tr>
<tr>
<td>LiveBench</td>
<td>46.26</td>
<td><strong>63.05</strong></td>
<td>54.03</td>
<td>52.92</td>
<td>55.41</td>
<td>53.11</td>
<td>54.21</td>
</tr>
</tbody>
</table></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
